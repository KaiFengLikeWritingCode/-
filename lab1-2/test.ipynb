{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-20T15:29:10.297281Z",
     "start_time": "2025-04-20T15:28:57.851245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "\n",
    "from utils import training, evaluation\n",
    "from models import bp_model, cnn_model\n",
    "\n",
    "# 全局配置\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "CRITERION = nn.CrossEntropyLoss()\n",
    "\n",
    "# 数据集加载与预处理\n",
    "def load_datasets():\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_ds_map = {}\n",
    "    test_ds_map  = {}\n",
    "    train_ds_map['mnist'], test_ds_map['mnist']   = MNIST('./data', True, download=True,  transform=transform), MNIST('./data', False, download=True, transform=transform)\n",
    "    train_ds_map['cifar10'], test_ds_map['cifar10'] = CIFAR10('./data', True, download=True, transform=transform), CIFAR10('./data', False, download=True, transform=transform)\n",
    "    return train_ds_map, test_ds_map\n",
    "\n",
    "train_ds_map, test_ds_map = load_datasets()\n",
    "input_shape_map = { ds: train_ds_map[ds][0][0].shape for ds in train_ds_map }\n",
    "\n",
    "# 统一测试集 DataLoader\n",
    "def get_test_loader(dataset, batch_size=64):\n",
    "    return DataLoader(test_ds_map[dataset], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_loader_map = { ds: get_test_loader(ds) for ds in test_ds_map }\n",
    "\n",
    "# 交叉验证划分\n",
    "def get_folds(dataset, n_splits=5, random_state=42):\n",
    "    from sklearn.model_selection import KFold\n",
    "    indices = np.arange(len(train_ds_map[dataset]))\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    return list(kf.split(indices))\n",
    "\n",
    "# 运行单次实验\n",
    "def run_experiment(dataset, model_type, epochs=10, batch_size=32, **model_kwargs):\n",
    "    test_accs = []\n",
    "    folds = get_folds(dataset)\n",
    "    for tr_idx, va_idx in folds:\n",
    "        tr_loader = DataLoader(Subset(train_ds_map[dataset], tr_idx), batch_size=batch_size, shuffle=True)\n",
    "        va_loader = DataLoader(Subset(train_ds_map[dataset], va_idx), batch_size=batch_size, shuffle=False)\n",
    "        # 模型构建\n",
    "        model_fn = bp_model.create_bp_model if model_type=='bp' else cnn_model.create_cnn_model\n",
    "        model = model_fn(input_shape_map[dataset], num_classes=10).to(DEVICE)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=model_kwargs.get('lr', 1e-3))\n",
    "        # 训练\n",
    "        training.train_model(model, tr_loader, va_loader, epochs, DEVICE, CRITERION, optimizer)\n",
    "        # 测试\n",
    "        _, acc = evaluation.evaluate_model(model, test_loader_map[dataset], DEVICE, CRITERION)\n",
    "        test_accs.append(acc)\n",
    "    return np.array(test_accs)\n",
    "\n",
    "models  = ['bp', 'cnn']\n",
    "datasets = ['mnist', 'cifar10']\n",
    "baseline = {}\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
