{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-20T16:37:27.506642100Z",
     "start_time": "2025-04-20T16:37:24.342244900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "\n",
    "from utils import training, evaluation\n",
    "from models import bp_model, cnn_model\n",
    "\n",
    "\n",
    "# 全局配置\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CRITERION = nn.CrossEntropyLoss()\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "\n",
    "# CIFAR-10 数据加载\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_ds = CIFAR10('./data', True, download=True, transform=transform)\n",
    "test_ds  = CIFAR10('./data', False, download=True, transform=transform)\n",
    "input_shape = train_ds[0][0].shape  # e.g. (3,32,32)\n",
    "\n",
    "# 激活函数映射\n",
    "act_map = {\n",
    "    'relu': nn.ReLU(),\n",
    "    'sigmoid': nn.Sigmoid(),\n",
    "    'leakyrelu': nn.LeakyReLU()\n",
    "}\n",
    "\n",
    "\n",
    "# def run_experiment(dataset, model_type, epochs=10, batch_size=32, **model_kwargs):\n",
    "#     test_accs = []\n",
    "#     folds = get_folds(dataset)\n",
    "#     for tr_idx, va_idx in folds:\n",
    "#         tr_loader = DataLoader(Subset(train_ds_map[dataset], tr_idx), batch_size=batch_size, shuffle=True)\n",
    "#         va_loader = DataLoader(Subset(train_ds_map[dataset], va_idx), batch_size=batch_size, shuffle=False)\n",
    "#         # 模型构建\n",
    "#         model_fn = bp_model.create_bp_model if model_type=='bp' else cnn_model.create_cnn_model\n",
    "#         model = model_fn(input_shape_map[dataset], num_classes=10).to(DEVICE)\n",
    "#         optimizer = optim.Adam(model.parameters(), lr=model_kwargs.get('lr', 1e-3))\n",
    "#         # 训练\n",
    "#         training.train_model(model, tr_loader, va_loader, epochs, DEVICE, CRITERION, optimizer)\n",
    "#         # 测试\n",
    "#         _, acc = evaluation.evaluate_model(model, test_loader_map[dataset], DEVICE, CRITERION)\n",
    "#         test_accs.append(acc)\n",
    "#     return np.array(test_accs)\n",
    "\n",
    "\n",
    "def run_epoch_experiment(model_type, activation_key):\n",
    "    \"\"\"\n",
    "    返回指定模型+激活函数下，每个 epoch 在验证集上的准确率列表\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "    activation = act_map[activation_key]\n",
    "\n",
    "    # 构建模型\n",
    "    # if model_type == 'bp':\n",
    "    #     model = CustomBPModel(input_shape, num_classes=10, activation=activation)\n",
    "    # else:\n",
    "    #     model = CustomCNNModel(input_shape, num_classes=10, activation=activation)\n",
    "    # model.to(DEVICE)\n",
    "    model_fn = bp_model.create_bp_model if model_type=='bp' else cnn_model.create_cnn_model\n",
    "    model = model_fn(input_shape, num_classes=10)\n",
    "    model.activation = activation\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    _, val_hist = training.train_model(\n",
    "        model, train_loader, val_loader,\n",
    "        epochs=EPOCHS, device=DEVICE,\n",
    "        criterion=CRITERION, optimizer=optimizer\n",
    "    )\n",
    "    return val_hist['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train loss: 1.4304, Train acc: 0.4899 | Val loss: 1.1884, Val acc: 0.5741\n",
      "Epoch 2/10 - Train loss: 1.0460, Train acc: 0.6332 | Val loss: 0.9767, Val acc: 0.6520\n",
      "Epoch 3/10 - Train loss: 0.8724, Train acc: 0.6963 | Val loss: 0.9045, Val acc: 0.6831\n",
      "Epoch 4/10 - Train loss: 0.7662, Train acc: 0.7331 | Val loss: 0.8099, Val acc: 0.7235\n",
      "Epoch 5/10 - Train loss: 0.6792, Train acc: 0.7630 | Val loss: 0.7996, Val acc: 0.7231\n",
      "Epoch 6/10 - Train loss: 0.6107, Train acc: 0.7859 | Val loss: 0.8145, Val acc: 0.7273\n",
      "Epoch 7/10 - Train loss: 0.5454, Train acc: 0.8111 | Val loss: 0.8389, Val acc: 0.7232\n",
      "Epoch 8/10 - Train loss: 0.4906, Train acc: 0.8298 | Val loss: 0.8381, Val acc: 0.7249\n",
      "Epoch 9/10 - Train loss: 0.4349, Train acc: 0.8484 | Val loss: 0.8326, Val acc: 0.7316\n",
      "Epoch 10/10 - Train loss: 0.3847, Train acc: 0.8653 | Val loss: 0.8779, Val acc: 0.7364\n",
      "Epoch 1/10 - Train loss: 1.4645, Train acc: 0.4738 | Val loss: 1.1945, Val acc: 0.5759\n",
      "Epoch 2/10 - Train loss: 1.0756, Train acc: 0.6229 | Val loss: 1.0058, Val acc: 0.6411\n",
      "Epoch 3/10 - Train loss: 0.9102, Train acc: 0.6821 | Val loss: 0.9310, Val acc: 0.6826\n",
      "Epoch 4/10 - Train loss: 0.7980, Train acc: 0.7211 | Val loss: 0.8493, Val acc: 0.7038\n",
      "Epoch 5/10 - Train loss: 0.7102, Train acc: 0.7540 | Val loss: 0.8182, Val acc: 0.7179\n",
      "Epoch 6/10 - Train loss: 0.6336, Train acc: 0.7795 | Val loss: 0.8297, Val acc: 0.7177\n",
      "Epoch 7/10 - Train loss: 0.5681, Train acc: 0.8042 | Val loss: 0.8073, Val acc: 0.7294\n",
      "Epoch 8/10 - Train loss: 0.5117, Train acc: 0.8221 | Val loss: 0.8248, Val acc: 0.7291\n",
      "Epoch 9/10 - Train loss: 0.4533, Train acc: 0.8426 | Val loss: 0.8756, Val acc: 0.7268\n",
      "Epoch 10/10 - Train loss: 0.4076, Train acc: 0.8568 | Val loss: 0.8628, Val acc: 0.7266\n",
      "Epoch 1/10 - Train loss: 1.4651, Train acc: 0.4749 | Val loss: 1.1722, Val acc: 0.5802\n",
      "Epoch 2/10 - Train loss: 1.0677, Train acc: 0.6258 | Val loss: 0.9695, Val acc: 0.6611\n",
      "Epoch 3/10 - Train loss: 0.8943, Train acc: 0.6906 | Val loss: 0.8916, Val acc: 0.6893\n",
      "Epoch 4/10 - Train loss: 0.7896, Train acc: 0.7273 | Val loss: 0.8469, Val acc: 0.7071\n",
      "Epoch 5/10 - Train loss: 0.7049, Train acc: 0.7553 | Val loss: 0.8352, Val acc: 0.7150\n",
      "Epoch 6/10 - Train loss: 0.6361, Train acc: 0.7823 | Val loss: 0.8081, Val acc: 0.7199\n",
      "Epoch 7/10 - Train loss: 0.5765, Train acc: 0.7998 | Val loss: 0.8100, Val acc: 0.7281\n",
      "Epoch 8/10 - Train loss: 0.5226, Train acc: 0.8183 | Val loss: 0.8296, Val acc: 0.7264\n",
      "Epoch 9/10 - Train loss: 0.4669, Train acc: 0.8382 | Val loss: 0.8342, Val acc: 0.7304\n",
      "Epoch 10/10 - Train loss: 0.4160, Train acc: 0.8563 | Val loss: 0.8841, Val acc: 0.7292\n",
      "Saved figure: activation_comparison_cnn.png\n"
     ]
    }
   ],
   "source": [
    "# models  = ['bp', 'cnn']\n",
    "# models  = ['cnn']\n",
    "\n",
    "\n",
    "activations = ['relu', 'sigmoid', 'leakyrelu']\n",
    "for model_type in ['cnn']:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for act in activations:\n",
    "        accs = run_epoch_experiment(model_type, act)\n",
    "        plt.plot(range(1, EPOCHS+1), accs, marker='o', label=act.capitalize())\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Validation Accuracy', fontsize=12)\n",
    "    plt.title(f'Activation Function Comparison ({model_type.upper()})', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    filename = f'activation_comparison_{model_type}.png'\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "    print(f'Saved figure: {filename}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-20T16:44:55.220759900Z",
     "start_time": "2025-04-20T16:37:29.950442800Z"
    }
   },
   "id": "59fbf6d9b230f774"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
